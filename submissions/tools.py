import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import statsmodels.api as sm
from statsmodels.formula.api import ols
import warnings
warnings.filterwarnings('ignore')

# é…ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

class DataProcessingTools:
    def __init__(self, df: pd.DataFrame):
        self.df = df.copy()
        self.cleaned_df = None
        self.visualizations = []
        self.stats_results = {}
        self.qar_core_fields = {}
        
        # QARå­—æ®µæ˜ å°„é…ç½® - æ”¯æŒç”¨æˆ·è‡ªå®šä¹‰å­—æ®µå
        self.field_mapping = {
            "timestamp": "Time",           # æ—¶é—´æˆ³å­—æ®µ
            "flight_phase": "FLT_PHASE",   # é£è¡Œé˜¶æ®µå­—æ®µ
            
            # å‘åŠ¨æœºå‚æ•°æ˜ å°„ï¼ˆæ”¯æŒå·¦å³å‘ï¼‰
            "n1_speed": ["LOCAL_N1_L", "LOCAL_N1_R"],
            "n2_speed": ["LOCAL_N2_SENSOR_L", "LOCAL_N2_SENSOR_R"],
            "egt": ["SEL_EGT_L", "SEL_EGT_R"],
            
            # é£è¡Œå‚æ•°æ˜ å°„
            "mach": ["CALC_MACH_NUM_L", "CALC_MACH_NUM_R"],
            "altitude": ["CALCULATED_ALT_L", "CALCULATED_ALT_R"],
            "temperature": ["AMBIENT_TMP_L", "AMBIENT_TMP_R"]
        }
        
        # é£è¡Œé˜¶æ®µæ•°å­—æ˜ å°„
        self.phase_mapping = {
            0: "èµ·é£å‰",
            1: "èµ·é£Takeoff", 
            2: "çˆ¬å‡CLB",
            3: "å·¡èˆªCRZ",
            4: "ä¸‹é™DES",
            5: "è¿›è¿‘APP",
            6: "ç›˜æ—‹/å¤é£GoAround",
            7: "ç»“æŸDone"
        }
        
        # å¤§æ–‡ä»¶å¤„ç†é…ç½®
        self.chunk_size = 50000  # åˆ†å—å¤§å°
        self.max_file_size = 300 * 1024 * 1024  # 300MBé™åˆ¶

    def parse_qar_data(self, file_path: str, file_type: str = "csv") -> pd.DataFrame:
        """è§£æQARæ•°æ®ï¼ˆæ”¯æŒCSVæ ¼å¼ï¼Œè‡ªåŠ¨å¤„ç†å­—æ®µæ˜ å°„å’Œå¤§æ–‡ä»¶ï¼‰"""
        import os
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(file_path)
        if file_size > self.max_file_size:
            print(f"âš ï¸  æ–‡ä»¶å¤§å°ä¸º {file_size/1024/1024:.1f}MBï¼Œè¶…è¿‡300MBé™åˆ¶ï¼Œå°†ä½¿ç”¨åˆ†å—å¤„ç†")
            return self._parse_large_qar_data(file_path, file_type)
        
        if file_type == "csv":
            # æ ‡å‡†CSVæ ¼å¼QARæ•°æ®è§£æ
            df = pd.read_csv(file_path)
            # åº”ç”¨å­—æ®µæ˜ å°„
            df = self._apply_field_mapping(df)
            # è‡ªåŠ¨è¯†åˆ«QARæ ¸å¿ƒå­—æ®µï¼ˆæ—¶é—´æˆ³ã€é£è¡Œé˜¶æ®µç­‰ï¼‰
            self._detect_qar_fields(df)
            return df
        elif file_type == "bin":
            # äºŒè¿›åˆ¶QARæ•°æ®è§£æï¼ˆå‚è€ƒæ°‘èˆªè§„èŒƒï¼‰
            import struct
            with open(file_path, "rb") as f:
                data = f.read()
            # å‡è®¾äºŒè¿›åˆ¶æ ¼å¼ä¸ºï¼šå¤´éƒ¨ï¼ˆ8å­—èŠ‚æ—¶é—´æˆ³ï¼‰+ å‚æ•°å—ï¼ˆæ¯ä¸ªå‚æ•°4å­—èŠ‚æµ®ç‚¹æ•°ï¼‰
            # å…·ä½“è§£æé€»è¾‘éœ€æ ¹æ®æ°‘èˆªQARæ ¼å¼è§„èŒƒè°ƒæ•´
            timestamps = []
            params = []
            for i in range(0, len(data), 8 + 4*len(self.expected_params)):
                timestamp = struct.unpack("d", data[i:i+8])[0]
                param_vals = struct.unpack(f"{len(self.expected_params)}f", data[i+8:i+8+4*len(self.expected_params)])
                timestamps.append(timestamp)
                params.append(param_vals)
            df = pd.DataFrame(params, columns=self.expected_params)
            df["timestamp"] = pd.to_datetime(timestamps, unit="s")
            self.qar_core_fields = {
                "timestamp": "timestamp",
                "flight_phase": "flight_phase",  # å‡è®¾è§£æååŒ…å«è¯¥å­—æ®µ
                # å…¶ä»–æ ¸å¿ƒå­—æ®µæ˜ å°„...
            }
            return df
        else:
            raise ValueError("ä¸æ”¯æŒçš„QARæ–‡ä»¶æ ¼å¼ï¼Œä»…æ”¯æŒcsvå’Œbin")
    
    def _parse_large_qar_data(self, file_path: str, file_type: str = "csv") -> pd.DataFrame:
        """åˆ†å—å¤„ç†å¤§æ–‡ä»¶"""
        if file_type != "csv":
            raise ValueError("å¤§æ–‡ä»¶å¤„ç†ä»…æ”¯æŒCSVæ ¼å¼")
        
        print(f"ğŸ”„  å¼€å§‹åˆ†å—è¯»å–å¤§æ–‡ä»¶ï¼Œæ¯å— {self.chunk_size} è¡Œ...")
        chunks = []
        
        for i, chunk in enumerate(pd.read_csv(file_path, chunksize=self.chunk_size)):
            print(f"   å¤„ç†ç¬¬ {i+1} å—...")
            # åº”ç”¨å­—æ®µæ˜ å°„
            chunk = self._apply_field_mapping(chunk)
            chunks.append(chunk)
            
            # å¦‚æœå·²ç»å¤„ç†äº†è¶³å¤Ÿå¤šçš„å—ç”¨äºæµ‹è¯•ï¼Œå¯ä»¥æå‰åœæ­¢ï¼ˆç”Ÿäº§ç¯å¢ƒå»æ‰ï¼‰
            if i >= 2:  # åªå¤„ç†å‰3å—ç”¨äºæµ‹è¯•ï¼Œå®é™…åº”è¯¥å¤„ç†å…¨éƒ¨
                print(f"   âš ï¸  æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰3å—")
                break
        
        if not chunks:
            raise ValueError("æœªè¯»å–åˆ°ä»»ä½•æ•°æ®å—")
        
        # åˆå¹¶æ‰€æœ‰å—
        df = pd.concat(chunks, ignore_index=True)
        print(f"âœ…  å¤§æ–‡ä»¶å¤„ç†å®Œæˆï¼Œæ€»è¡Œæ•°: {len(df)}")
        
        # è‡ªåŠ¨è¯†åˆ«å­—æ®µ
        self._detect_qar_fields(df)
        return df
    
    def _apply_field_mapping(self, df: pd.DataFrame) -> pd.DataFrame:
        """åº”ç”¨å­—æ®µåæ˜ å°„ï¼Œå°†QARç¼©å†™æ˜ å°„åˆ°ç¨‹åºæœŸæœ›çš„å­—æ®µå"""
        mapped_df = df.copy()
        
        # æ—¶é—´æˆ³æ˜ å°„
        if self.field_mapping["timestamp"] in df.columns:
            mapped_df = mapped_df.rename(columns={self.field_mapping["timestamp"]: "Time"})
        
        # é£è¡Œé˜¶æ®µæ˜ å°„
        if self.field_mapping["flight_phase"] in df.columns:
            mapped_df = mapped_df.rename(columns={self.field_mapping["flight_phase"]: "FLT_PHASE"})
            # å°†æ•°å­—é˜¶æ®µæ˜ å°„ä¸ºå¯è¯»åç§°
            if "FLT_PHASE" in mapped_df.columns:
                mapped_df["FLT_PHASE"] = mapped_df["FLT_PHASE"].map(self.phase_mapping)
        
        # å‘åŠ¨æœºå‚æ•°æ˜ å°„ï¼ˆæ”¯æŒå·¦å³å‘ï¼‰
        for standard_name, qar_names in self.field_mapping.items():
            if standard_name in ["n1_speed", "n2_speed", "egt"]:
                for qar_name in qar_names:
                    if qar_name in df.columns:
                        # ä¿ç•™åŸå§‹åˆ—ï¼ŒåŒæ—¶æ·»åŠ æ ‡å‡†åç§°åˆ—ï¼ˆç”¨äºåç»­åˆ†æï¼‰
                        if standard_name not in mapped_df.columns:
                            mapped_df[standard_name] = mapped_df[qar_name]
        
        # é£è¡Œå‚æ•°æ˜ å°„
        for standard_name, qar_names in self.field_mapping.items():
            if standard_name in ["mach", "altitude", "temperature"]:
                for qar_name in qar_names:
                    if qar_name in df.columns:
                        if standard_name not in mapped_df.columns:
                            mapped_df[standard_name] = mapped_df[qar_name]
        
        return mapped_df
    
    def _detect_qar_fields(self, df: pd.DataFrame):
        """è‡ªåŠ¨æ£€æµ‹å¹¶è®°å½•QARæ ¸å¿ƒå­—æ®µ"""
        self.qar_core_fields = {
            "timestamp": "Time" if "Time" in df.columns else None,
            "flight_phase": "FLT_PHASE" if "FLT_PHASE" in df.columns else None,
            "engine_params": [col for col in df.columns if col in ["n1_speed", "n2_speed", "egt"]],
            "flight_params": [col for col in df.columns if col in ["mach", "altitude", "temperature"]]
        }
        
        # å¦‚æœæ ‡å‡†å­—æ®µä¸å­˜åœ¨ï¼Œå°è¯•ä»åŸå§‹å­—æ®µä¸­è¯†åˆ«
        if not self.qar_core_fields["engine_params"]:
            self.qar_core_fields["engine_params"] = [col for col in df.columns if any(p in col.lower() for p in ["local_n1", "local_n2", "sel_egt"])]
        
        if not self.qar_core_fields["flight_params"]:
            self.qar_core_fields["flight_params"] = [col for col in df.columns if any(p in col.lower() for p in ["calc_mach", "calculated_alt", "ambient_tmp"])]
        
        print(f"ğŸ”  æ£€æµ‹åˆ°QARæ ¸å¿ƒå­—æ®µ:")
        print(f"   æ—¶é—´æˆ³: {self.qar_core_fields['timestamp']}")
        print(f"   é£è¡Œé˜¶æ®µ: {self.qar_core_fields['flight_phase']}")
        print(f"   å‘åŠ¨æœºå‚æ•°: {self.qar_core_fields['engine_params']}")
        print(f"   é£è¡Œå‚æ•°: {self.qar_core_fields['flight_params']}")
    
    def get_parameter_categories(self, df: pd.DataFrame) -> dict:
        """è·å–å‚æ•°åˆ†ç±»ï¼Œç”¨äºç­›é€‰ç•Œé¢"""
        categories = {
            "æ ¸å¿ƒå‚æ•°": [],
            "å‘åŠ¨æœºå‚æ•°": [],
            "é£è¡Œå‚æ•°": [],
            "ç³»ç»Ÿå‚æ•°": [],
            "ç¯å¢ƒå‚æ•°": [],
            "å…¶ä»–å‚æ•°": []
        }
        
        # æ ¸å¿ƒå‚æ•°ï¼ˆå¿…é¡»ä¿ç•™ï¼‰
        core_params = ["Time", "FLT_PHASE"]
        for param in core_params:
            if param in df.columns:
                categories["æ ¸å¿ƒå‚æ•°"].append(param)
        
        # å‘åŠ¨æœºå‚æ•°
        engine_keywords = ["n1", "n2", "egt", "thrust", "fuel", "engine", "LOCAL_N1", "LOCAL_N2", "SEL_EGT"]
        for col in df.columns:
            if any(keyword.lower() in col.lower() for keyword in engine_keywords):
                categories["å‘åŠ¨æœºå‚æ•°"].append(col)
        
        # é£è¡Œå‚æ•°
        flight_keywords = ["altitude", "speed", "mach", "angle", "pitch", "roll", "yaw", "vert_speed", 
                          "CALCULATED_ALT", "CALC_MACH", "airspeed", "velocity"]
        for col in df.columns:
            if any(keyword.lower() in col.lower() for keyword in flight_keywords):
                categories["é£è¡Œå‚æ•°"].append(col)
        
        # ç³»ç»Ÿå‚æ•°
        system_keywords = ["hydraulic", "electric", "pressure", "voltage", "current", "pump", "valve", "switch"]
        for col in df.columns:
            if any(keyword.lower() in col.lower() for keyword in system_keywords) and col not in categories["å‘åŠ¨æœºå‚æ•°"] + categories["é£è¡Œå‚æ•°"]:
                categories["ç³»ç»Ÿå‚æ•°"].append(col)
        
        # ç¯å¢ƒå‚æ•°
        env_keywords = ["ambient", "temperature", "pressure", "wind", "weather", "tmp", "TMP"]
        for col in df.columns:
            if any(keyword.lower() in col.lower() for keyword in env_keywords) and col not in categories["é£è¡Œå‚æ•°"]:
                categories["ç¯å¢ƒå‚æ•°"].append(col)
        
        # å…¶ä»–å‚æ•°ï¼ˆæœªåˆ†ç±»çš„ï¼‰
        all_categorized = set()
        for cat_list in categories.values():
            all_categorized.update(cat_list)
        
        for col in df.columns:
            if col not in all_categorized:
                categories["å…¶ä»–å‚æ•°"].append(col)
        
        # ç§»é™¤ç©ºçš„åˆ†ç±»
        categories = {k: v for k, v in categories.items() if v}
        
        return categories
    
    def filter_parameters(self, df: pd.DataFrame, keep_params: list) -> pd.DataFrame:
        """æ ¹æ®é€‰æ‹©çš„å‚æ•°åˆ—è¡¨ç­›é€‰æ•°æ®"""
        if not keep_params:
            print("âš ï¸  æœªé€‰æ‹©ä»»ä½•å‚æ•°ï¼Œè¿”å›åŸå§‹æ•°æ®")
            return df
        
        # ç¡®ä¿æ ¸å¿ƒå‚æ•°è¢«ä¿ç•™
        required_params = ["Time", "FLT_PHASE"]
        for param in required_params:
            if param in df.columns and param not in keep_params:
                keep_params.append(param)
        
        # æ£€æŸ¥é€‰æ‹©çš„å‚æ•°æ˜¯å¦å­˜åœ¨äºæ•°æ®ä¸­
        available_params = [p for p in keep_params if p in df.columns]
        missing_params = [p for p in keep_params if p not in df.columns]
        
        if missing_params:
            print(f"âš ï¸  ä»¥ä¸‹å‚æ•°ä¸å­˜åœ¨ï¼Œå°†è¢«å¿½ç•¥: {missing_params}")
        
        print(f"ğŸ“Š ç­›é€‰åä¿ç•™ {len(available_params)} ä¸ªå‚æ•°: {available_params}")
        return df[available_params]
    
    def get_flight_phases_summary(self, df: pd.DataFrame) -> dict:
        """è·å–é£è¡Œé˜¶æ®µæ•°æ®åˆ†å¸ƒæ‘˜è¦"""
        if "FLT_PHASE" not in df.columns:
            return {}
        
        phase_counts = df["FLT_PHASE"].value_counts().to_dict()
        total_rows = len(df)
        
        summary = {}
        for phase, count in phase_counts.items():
            percentage = (count / total_rows) * 100
            summary[phase] = {
                "rows": count,
                "percentage": round(percentage, 2)
            }
        
        return summary
    
    def filter_flight_phases(self, df: pd.DataFrame, selected_phases: list) -> pd.DataFrame:
        """æ ¹æ®é€‰æ‹©çš„é£è¡Œé˜¶æ®µç­›é€‰æ•°æ®"""
        if not selected_phases:
            print("âš ï¸  æœªé€‰æ‹©ä»»ä½•é£è¡Œé˜¶æ®µï¼Œè¿”å›åŸå§‹æ•°æ®")
            return df
        
        if "FLT_PHASE" not in df.columns:
            print("âš ï¸  æ•°æ®ä¸­ä¸å­˜åœ¨é£è¡Œé˜¶æ®µåˆ—ï¼Œè¿”å›åŸå§‹æ•°æ®")
            return df
        
        # åº”ç”¨ç­›é€‰
        filtered_df = df[df["FLT_PHASE"].isin(selected_phases)]
        
        original_rows = len(df)
        filtered_rows = len(filtered_df)
        reduction = ((original_rows - filtered_rows) / original_rows) * 100
        
        print(f"âœˆï¸  é£è¡Œé˜¶æ®µç­›é€‰: ä¿ç•™ {len(selected_phases)} ä¸ªé˜¶æ®µ")
        print(f"   åŸå§‹æ•°æ®: {original_rows} è¡Œ")
        print(f"   ç­›é€‰å: {filtered_rows} è¡Œ")
        print(f"   æ•°æ®å‡å°‘: {reduction:.1f}%")
        
        return filtered_df
    
    def estimate_report_tokens(self, df: pd.DataFrame, eda_results: dict, stats_results: dict) -> int:
        """ä¼°ç®—ç”ŸæˆæŠ¥å‘Šæ‰€éœ€çš„tokenæ•°é‡"""
        # åŸºç¡€tokenï¼ˆæç¤ºè¯æ¨¡æ¿ï¼‰
        base_tokens = 200
        
        # æ•°æ®æ‘˜è¦token
        data_tokens = len(df) * 2  # æ¯è¡Œæ•°æ®çº¦2ä¸ªtokenï¼ˆæ‘˜è¦ï¼‰
        if data_tokens > 500:
            data_tokens = 500  # é™åˆ¶æœ€å¤§å€¼
        
        # EDAç»“æœtoken
        eda_tokens = 0
        if eda_results:
            eda_text = str(eda_results)
            eda_tokens = len(eda_text) // 4  # ç²—ç•¥ä¼°ç®—
        
        # ç»Ÿè®¡ç»“æœtoken
        stats_tokens = 0
        if stats_results:
            stats_text = str(stats_results)
            stats_tokens = len(stats_text) // 4  # ç²—ç•¥ä¼°ç®—
        
        # æ€»tokenä¼°ç®—
        total_tokens = base_tokens + data_tokens + eda_tokens + stats_tokens
        
        print(f"ğŸ“ Tokenä¼°ç®—:")
        print(f"   åŸºç¡€æç¤ºè¯: {base_tokens}")
        print(f"   æ•°æ®æ‘˜è¦: {data_tokens}")
        print(f"   EDAç»“æœ: {eda_tokens}")
        print(f"   ç»Ÿè®¡ç»“æœ: {stats_tokens}")
        print(f"   é¢„ä¼°æ€»è®¡: {total_tokens} tokens")
        
        return total_tokens
    
    def validate_token_limit(self, total_tokens: int, limit: int = 32768) -> tuple:
        """éªŒè¯tokenæ•°é‡æ˜¯å¦è¶…é™"""
        safe_limit = limit * 0.8  # ä½¿ç”¨80%ä½œä¸ºå®‰å…¨çº¿
        is_safe = total_tokens <= safe_limit
        margin = limit - total_tokens
        
        return is_safe, margin, safe_limit
        
    # 1. è‡ªåŠ¨æ•°æ®æ¸…æ´—
    def clean_data(self) -> dict:
        log = []
        log.append(f"åŸå§‹QARæ•°æ®è§„æ¨¡: {self.df.shape[0]} è¡Œ Ã— {self.df.shape[1]} åˆ—")

        # ç¡®ä¿qar_core_fieldså·²åˆå§‹åŒ–
        if not self.qar_core_fields:
            self._detect_qar_fields(self.df)

        # 1. é£è¡Œé˜¶æ®µè¿‡æ»¤ï¼ˆä¿ç•™æœ‰æ•ˆé˜¶æ®µï¼‰
        if self.qar_core_fields.get("flight_phase"):
            valid_phases = ["èµ·é£Takeoff", "å·¡èˆªCRZ", "è¿›è¿‘APP", "èµ·é£å‰", "ä¸‹é™DES", "ç›˜æ—‹/å¤é£GoAround"]  # æœ‰æ•ˆé£è¡Œé˜¶æ®µ
            phase_col = self.qar_core_fields["flight_phase"]
            if phase_col in self.df.columns:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ•ˆé˜¶æ®µ
                valid_mask = self.df[phase_col].isin(valid_phases)
                if valid_mask.any():
                    invalid_count = (~valid_mask).sum()
                    if invalid_count > 0:
                        self.df = self.df[valid_mask]
                        log.append(f"è¿‡æ»¤æ— æ•ˆé£è¡Œé˜¶æ®µæ•°æ®ï¼š{invalid_count} è¡Œï¼ˆä¿ç•™ï¼š{valid_phases}ï¼‰")
                else:
                    log.append(f"âš ï¸  é£è¡Œé˜¶æ®µåˆ— {phase_col} ä¸åŒ…å«æœ‰æ•ˆé˜¶æ®µå€¼ï¼Œè·³è¿‡è¿‡æ»¤")
            else:
                log.append(f"âš ï¸  é£è¡Œé˜¶æ®µåˆ— {phase_col} ä¸å­˜åœ¨ï¼Œè·³è¿‡è¿‡æ»¤")

        # 2. é‡å¤å€¼å¤„ç†ï¼ˆæ—¶é—´æˆ³+å…³é”®å‚æ•°è”åˆå»é‡ï¼‰
        if self.qar_core_fields.get("timestamp") and self.qar_core_fields["timestamp"] in self.df.columns:
            dup_cols = [self.qar_core_fields["timestamp"]]
            # åªæ·»åŠ å­˜åœ¨çš„å¼•æ“å‚æ•°
            for param in self.qar_core_fields["engine_params"][:3]:
                if param in self.df.columns:
                    dup_cols.append(param)
            
            if len(dup_cols) > 1:
                dup_count = self.df.duplicated(subset=dup_cols).sum()
                if dup_count > 0:
                    self.df = self.df.drop_duplicates(subset=dup_cols)
                    log.append(f"åˆ é™¤é‡å¤æ—¶é—´æˆ³è®°å½•ï¼š{dup_count} è¡Œ")
            else:
                log.append("âš ï¸  æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å»é‡åˆ—ï¼Œè·³è¿‡é‡å¤å€¼å¤„ç†")
        else:
            log.append("âš ï¸  æ²¡æœ‰æ‰¾åˆ°æ—¶é—´æˆ³åˆ—ï¼Œè·³è¿‡é‡å¤å€¼å¤„ç†")

        # 3. ç¼ºå¤±å€¼å¤„ç†ï¼ˆåŒºåˆ†å…³é”®å‚æ•°å’Œéå…³é”®å‚æ•°ï¼‰
        missing_cols = self.df.isnull().sum()[self.df.isnull().sum() > 0].index
        for col in missing_cols:
            if col in self.qar_core_fields.get("engine_params", []):
                # å‘åŠ¨æœºå…³é”®å‚æ•°ï¼šç”¨å‰5ç§’æ»‘åŠ¨å¹³å‡å¡«å……
                if hasattr(self.df[col], 'rolling'):
                    self.df[col] = self.df[col].fillna(self.df[col].rolling(window=5, min_periods=1).mean())
                    log.append(f"å‘åŠ¨æœºå‚æ•°[{col}]ç¼ºå¤±å€¼å¡«å……ï¼šæ»‘åŠ¨å¹³å‡ï¼ˆçª—å£5ç§’ï¼‰")
                else:
                    median_val = self.df[col].median()
                    self.df[col] = self.df[col].fillna(median_val)
                    log.append(f"å‘åŠ¨æœºå‚æ•°[{col}]ç¼ºå¤±å€¼å¡«å……: ä¸­ä½æ•°({median_val})")
            else:
                # éå…³é”®å‚æ•°ï¼šä¿ç•™åŸå§‹å¡«å……é€»è¾‘
                if self.df[col].dtype == 'object':
                    mode_val = self.df[col].mode()[0] if len(self.df[col].mode()) > 0 else "æœªçŸ¥"
                    self.df[col] = self.df[col].fillna(mode_val)
                    log.append(f"åˆ†ç±»å˜é‡[{col}]ç¼ºå¤±å€¼å¡«å……: ä¼—æ•°({mode_val})")
                else:
                    median_val = self.df[col].median()
                    self.df[col] = self.df[col].fillna(median_val)
                    log.append(f"æ•°å€¼å˜é‡[{col}]ç¼ºå¤±å€¼å¡«å……: ä¸­ä½æ•°({median_val})")

        # 4. å¼‚å¸¸å€¼å¤„ç†ï¼ˆæ›¿æ¢ä¸ºQARè¡Œä¸šé˜ˆå€¼ï¼‰
        # å‘åŠ¨æœºå‚æ•°é˜ˆå€¼ï¼ˆç¤ºä¾‹ï¼‰
        engine_thresholds = {
            "n1_speed": (20.0, 100.0),  # N1è½¬é€Ÿæ­£å¸¸èŒƒå›´20%-100%
            "n2_speed": (50.0, 105.0),  # N2è½¬é€Ÿæ­£å¸¸èŒƒå›´50%-105%
            "fuel_flow": (0.0, 5000.0)  # ç‡ƒæ²¹æµé‡æ­£å¸¸èŒƒå›´0-5000kg/h
        }
        # é£è¡Œå‚æ•°é˜ˆå€¼ï¼ˆç¤ºä¾‹ï¼‰
        flight_thresholds = {
            "altitude": (-100, 15000),  # é«˜åº¦æ­£å¸¸èŒƒå›´-100è‡³15000ç±³
            "airspeed": (0, 600)        # ç©ºé€Ÿæ­£å¸¸èŒƒå›´0-600km/h
        }
        
        # åº”ç”¨é˜ˆå€¼è¿‡æ»¤ - å‘åŠ¨æœºå‚æ•°
        for col in self.qar_core_fields.get("engine_params", []):
            if col in engine_thresholds and col in self.df.columns:
                lower, upper = engine_thresholds[col]
                outliers = self.df[(self.df[col] < lower) | (self.df[col] > upper)]
                if not outliers.empty:
                    self.df.loc[self.df[col] < lower, col] = lower
                    self.df.loc[self.df[col] > upper, col] = upper
                    log.append(f"å‘åŠ¨æœºå‚æ•°[{col}]å¼‚å¸¸å€¼å¤„ç†ï¼š{len(outliers)} ä¸ªå€¼æ›¿æ¢ä¸ºè¡Œä¸šé˜ˆå€¼({lower}-{upper})")
        
        # åº”ç”¨é˜ˆå€¼è¿‡æ»¤ - é£è¡Œå‚æ•°
        for col in self.qar_core_fields.get("flight_params", []):
            if col in flight_thresholds and col in self.df.columns:
                lower, upper = flight_thresholds[col]
                outliers = self.df[(self.df[col] < lower) | (self.df[col] > upper)]
                if not outliers.empty:
                    self.df.loc[self.df[col] < lower, col] = lower
                    self.df.loc[self.df[col] > upper, col] = upper
                    log.append(f"é£è¡Œå‚æ•°[{col}]å¼‚å¸¸å€¼å¤„ç†ï¼š{len(outliers)} ä¸ªå€¼æ›¿æ¢ä¸ºè¡Œä¸šé˜ˆå€¼({lower}-{upper})")

        self.cleaned_df = self.df
        log.append(f"æ¸…æ´—åQARæ•°æ®è§„æ¨¡: {self.cleaned_df.shape[0]} è¡Œ Ã— {self.cleaned_df.shape[1]} åˆ—")
        return {"æ¸…æ´—æ—¥å¿—": log, "æ¸…æ´—åæ•°æ®": self.cleaned_df}

    # 2. æ¢ç´¢æ€§æ•°æ®åˆ†æ
    def eda_analysis(self) -> dict:
        if self.cleaned_df is None:
            self.clean_data()
        
        # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
        if self.cleaned_df is None or self.cleaned_df.empty:
            print("âš ï¸  æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡ŒEDAåˆ†æ")
            return {
                "æ•°å€¼å˜é‡æè¿°ç»Ÿè®¡": {},
                "åˆ†ç±»å˜é‡åˆ†å¸ƒ": {},
                "æ•°å€¼å˜é‡ç›¸å…³æ€§": None,
                "QARæ—¶é—´åºåˆ—æ»‘åŠ¨çª—å£ç»Ÿè®¡": {},
                "QARé£è¡Œé˜¶æ®µåˆ†ç»„ç»Ÿè®¡": {}
            }
        
        # åŸºç¡€ç»Ÿè®¡ä¿æŒä¸å˜
        numeric_stats = self.cleaned_df.describe().round(2)
        cat_cols = self.cleaned_df.select_dtypes(include=['object', 'category']).columns
        cat_dist = {col: self.cleaned_df[col].value_counts().to_dict() for col in cat_cols}
        num_cols = self.cleaned_df.select_dtypes(include=[np.number]).columns
        corr_matrix = self.cleaned_df[num_cols].corr().round(2) if len(num_cols)>=2 else None

        # QARä¸“å±åˆ†æï¼šæ—¶é—´åºåˆ—æ»‘åŠ¨çª—å£ç»Ÿè®¡
        time_series_stats = {}
        if self.qar_core_fields.get("timestamp") and self.qar_core_fields["timestamp"] in self.cleaned_df.columns:
            # æŒ‰æ—¶é—´æˆ³æ’åº
            self.cleaned_df = self.cleaned_df.sort_values(by=self.qar_core_fields["timestamp"])
            # 10ç§’æ»‘åŠ¨çª—å£ç»Ÿè®¡ï¼ˆå…³é”®å‚æ•°ï¼‰
            window_params = []
            if self.qar_core_fields.get("engine_params"):
                window_params.extend(self.qar_core_fields["engine_params"])
            if self.qar_core_fields.get("flight_params"):
                window_params.extend(self.qar_core_fields["flight_params"][:2])
            
            for col in window_params:
                if col in self.cleaned_df.columns:
                    time_series_stats[f"{col}_10s_mean"] = self.cleaned_df[col].rolling(window=10, min_periods=1).mean().describe().round(2)
                    time_series_stats[f"{col}_10s_std"] = self.cleaned_df[col].rolling(window=10, min_periods=1).std().describe().round(2)

        # QARä¸“å±åˆ†æï¼šé£è¡Œé˜¶æ®µåˆ†ç»„ç»Ÿè®¡
        phase_stats = {}
        if self.qar_core_fields.get("flight_phase") and self.qar_core_fields["flight_phase"] in self.cleaned_df.columns:
            phase_col = self.qar_core_fields["flight_phase"]
            if window_params:
                valid_params = [col for col in window_params if col in self.cleaned_df.columns]
                if valid_params:
                    phase_stats = self.cleaned_df.groupby(phase_col)[valid_params].agg(["mean", "std", "max"]).round(2).to_dict()

        return {
            "æ•°å€¼å˜é‡æè¿°ç»Ÿè®¡": numeric_stats,
            "åˆ†ç±»å˜é‡åˆ†å¸ƒ": cat_dist,
            "æ•°å€¼å˜é‡ç›¸å…³æ€§": corr_matrix,
            "QARæ—¶é—´åºåˆ—æ»‘åŠ¨çª—å£ç»Ÿè®¡": time_series_stats,  # æ–°å¢
            "QARé£è¡Œé˜¶æ®µåˆ†ç»„ç»Ÿè®¡": phase_stats  # æ–°å¢
        }
    # 3. è‡ªåŠ¨åŒ–å¯è§†åŒ–
    def generate_visuals(self, save_dir: str = "visuals/") -> list:
        import os
        os.makedirs(save_dir, exist_ok=True)
        self.visualizations = []

        if self.cleaned_df is None:
            self.clean_data()

        # æ•°å€¼å˜é‡åˆ†å¸ƒç›´æ–¹å›¾
        num_cols = self.cleaned_df.select_dtypes(include=[np.number]).columns
        if len(num_cols) > 0:
            plt.figure(figsize=(12, 8))
            for i, col in enumerate(num_cols[:4]):  # æœ€å¤šæ˜¾ç¤º4ä¸ªå˜é‡
                plt.subplot(2, 2, i+1)
                sns.histplot(self.cleaned_df[col], kde=True, bins=20)
                plt.title(f"{col} åˆ†å¸ƒ")
            hist_path = f"{save_dir}/numeric_dist.png"
            plt.savefig(hist_path, dpi=300, bbox_inches='tight')
            plt.close()
            self.visualizations.append(("æ•°å€¼å˜é‡åˆ†å¸ƒ", hist_path))

        # åˆ†ç±»å˜é‡è®¡æ•°å›¾
        cat_cols = self.cleaned_df.select_dtypes(include=['object', 'category']).columns
        if len(cat_cols) > 0:
            plt.figure(figsize=(12, 8))
            for i, col in enumerate(cat_cols[:4]):
                plt.subplot(2, 2, i+1)
                sns.countplot(x=col, data=self.cleaned_df)
                plt.title(f"{col} åˆ†å¸ƒ")
                plt.xticks(rotation=45)
            count_path = f"{save_dir}/cat_count.png"
            plt.savefig(count_path, dpi=300, bbox_inches='tight')
            plt.close()
            self.visualizations.append(("åˆ†ç±»å˜é‡åˆ†å¸ƒ", count_path))

        # ç›¸å…³æ€§çƒ­åŠ›å›¾
        if len(num_cols) >= 2:
            plt.figure(figsize=(10, 8))
            sns.heatmap(self.cleaned_df[num_cols].corr(), annot=True, cmap='coolwarm')
            plt.title("æ•°å€¼å˜é‡ç›¸å…³æ€§çƒ­åŠ›å›¾")
            corr_path = f"{save_dir}/corr_heatmap.png"
            plt.savefig(corr_path, dpi=300, bbox_inches='tight')
            plt.close()
            self.visualizations.append(("ç›¸å…³æ€§çƒ­åŠ›å›¾", corr_path))
        
        # QARæ—¶é—´åºåˆ—å›¾
        if self.qar_core_fields.get("timestamp") and self.qar_core_fields["timestamp"] in self.cleaned_df.columns:
            time_col = self.qar_core_fields["timestamp"]
            # é€‰æ‹©3ä¸ªå…³é”®å‚æ•°ç»˜åˆ¶æ—¶é—´åºåˆ—
            plot_params = []
            if self.qar_core_fields.get("engine_params") and len(self.qar_core_fields["engine_params"]) >= 2:
                plot_params.extend(self.qar_core_fields["engine_params"][:2])
            if self.qar_core_fields.get("flight_params") and len(self.qar_core_fields["flight_params"]) >= 1:
                plot_params.extend(self.qar_core_fields["flight_params"][:1])
            
            if plot_params:
                plt.figure(figsize=(15, 10))
                for i, col in enumerate(plot_params):
                    if col in self.cleaned_df.columns:
                        plt.subplot(len(plot_params), 1, i+1)
                        plt.plot(self.cleaned_df[time_col], self.cleaned_df[col], linewidth=0.8)
                        plt.title(f"{col} éšæ—¶é—´å˜åŒ–è¶‹åŠ¿")
                        plt.xticks(rotation=45)
                ts_path = f"{save_dir}/qar_time_series.png"
                plt.tight_layout()
                plt.savefig(ts_path, dpi=300, bbox_inches='tight')
                plt.close()
                self.visualizations.append(("QARå‚æ•°æ—¶é—´åºåˆ—è¶‹åŠ¿", ts_path))

        # QARä¸“å±å¯è§†åŒ–ï¼šé£è¡Œé˜¶æ®µå‚æ•°ç®±çº¿å›¾
        if self.qar_core_fields.get("flight_phase") and self.qar_core_fields["flight_phase"] in self.cleaned_df.columns:
            phase_col = self.qar_core_fields["flight_phase"]
            if self.qar_core_fields.get("engine_params") and len(self.qar_core_fields["engine_params"]) >= 2:
                plt.figure(figsize=(12, 8))
                for i, col in enumerate(self.qar_core_fields["engine_params"][:2]):
                    if col in self.cleaned_df.columns:
                        plt.subplot(2, 1, i+1)
                        sns.boxplot(x=phase_col, y=col, data=self.cleaned_df)
                        plt.title(f"{col} åœ¨ä¸åŒé£è¡Œé˜¶æ®µçš„åˆ†å¸ƒ")
                phase_path = f"{save_dir}/qar_phase_boxplot.png"
                plt.tight_layout()
                plt.savefig(phase_path, dpi=300, bbox_inches='tight')
                plt.close()
                self.visualizations.append(("é£è¡Œé˜¶æ®µå‚æ•°åˆ†å¸ƒå¯¹æ¯”", phase_path))

        # QARä¸“å±å¯è§†åŒ–ï¼šå‘åŠ¨æœºå‚æ•°ç›¸å…³æ€§æ•£ç‚¹å›¾
        if self.qar_core_fields.get("engine_params") and len(self.qar_core_fields["engine_params"]) >= 2:
            col1, col2 = self.qar_core_fields["engine_params"][0], self.qar_core_fields["engine_params"][1]
            if col1 in self.cleaned_df.columns and col2 in self.cleaned_df.columns:
                plt.figure(figsize=(10, 8))
                if self.qar_core_fields.get("flight_phase") and self.qar_core_fields["flight_phase"] in self.cleaned_df.columns:
                    sns.scatterplot(x=col1, y=col2, hue=self.qar_core_fields["flight_phase"], data=self.cleaned_df)
                else:
                    sns.scatterplot(x=col1, y=col2, data=self.cleaned_df)
                plt.title(f"{col1} ä¸ {col2} çš„ç›¸å…³æ€§ï¼ˆæŒ‰é£è¡Œé˜¶æ®µåˆ†ç»„ï¼‰")
                corr_scatter_path = f"{save_dir}/qar_engine_corr.png"
                plt.savefig(corr_scatter_path, dpi=300, bbox_inches='tight')
                plt.close()
                self.visualizations.append(("å‘åŠ¨æœºå‚æ•°ç›¸å…³æ€§æ•£ç‚¹å›¾", corr_scatter_path))

            
        return self.visualizations

    # 4. ç»Ÿè®¡æ£€éªŒ
    def statistical_tests(self, target_col: str = None) -> dict:
        if self.cleaned_df is None:
            self.clean_data()
        
        # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
        if self.cleaned_df is None or self.cleaned_df.empty:
            print("âš ï¸  æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œç»Ÿè®¡æ£€éªŒ")
            return {}

        results = {}
        num_cols = self.cleaned_df.select_dtypes(include=[np.number]).columns
        cat_cols = self.cleaned_df.select_dtypes(include=['object', 'category']).columns

        # Pearsonç›¸å…³æ€§æ£€éªŒ
        if len(num_cols) >= 2:
            corr_res = {}
            for i, col1 in enumerate(num_cols):
                for j, col2 in enumerate(num_cols):
                    if i < j:
                        corr, p_val = stats.pearsonr(self.cleaned_df[col1], self.cleaned_df[col2])
                        corr_res[f"{col1} vs {col2}"] = {
                            "ç›¸å…³ç³»æ•°": round(corr, 3),
                            "på€¼": round(p_val, 5),
                            "æ˜¾è‘—æ€§": "æ˜¾è‘—" if p_val < 0.05 else "ä¸æ˜¾è‘—"
                        }
            results["Pearsonç›¸å…³æ€§æ£€éªŒ"] = corr_res

        # ç›®æ ‡å˜é‡ç›¸å…³æ£€éªŒ
        if target_col and target_col in self.cleaned_df.columns:
            # å¡æ–¹æ£€éªŒï¼ˆåˆ†ç±»å˜é‡ï¼‰
            if target_col in cat_cols:
                chi2_res = {}
                for col in cat_cols:
                    if col != target_col:
                        cont_table = pd.crosstab(self.cleaned_df[target_col], self.cleaned_df[col])
                        chi2, p_val, dof, _ = stats.chi2_contingency(cont_table)
                        chi2_res[f"{target_col} vs {col}"] = {
                            "å¡æ–¹å€¼": round(chi2, 3),
                            "på€¼": round(p_val, 5),
                            "æ˜¾è‘—æ€§": "æ˜¾è‘—" if p_val < 0.05 else "ä¸æ˜¾è‘—"
                        }
                results["å¡æ–¹æ£€éªŒ"] = chi2_res

                # ANOVAï¼ˆåˆ†ç±»ç›®æ ‡ vs æ•°å€¼ç‰¹å¾ï¼‰
                anova_res = {}
                for col in num_cols:
                    model = ols(f"{col} ~ C({target_col})", data=self.cleaned_df).fit()
                    anova_table = sm.stats.anova_lm(model, typ=2)
                    f_val = anova_table['F'].iloc[0]
                    p_val = anova_table['PR(>F)'].iloc[0]
                    anova_res[f"{col} vs {target_col}"] = {
                        "Få€¼": round(f_val, 3),
                        "på€¼": round(p_val, 5),
                        "æ˜¾è‘—æ€§": "æ˜¾è‘—" if p_val < 0.05 else "ä¸æ˜¾è‘—"
                    }
                results["æ–¹å·®åˆ†æ(ANOVA)"] = anova_res
        qar_specific_tests = {}
        
        # 1. å‘åŠ¨æœºæ¨åŠ›ä¸é£è¡Œé€Ÿåº¦çš„ç›¸å…³æ€§ï¼ˆæ•ˆç‡è¯„ä¼°ï¼‰
        if self.qar_core_fields.get("engine_params") and self.qar_core_fields.get("flight_params"):
            engine_params_lower = [col.lower() for col in self.qar_core_fields["engine_params"]]
            flight_params_lower = [col.lower() for col in self.qar_core_fields["flight_params"]]
            
            if "thrust" in engine_params_lower and "airspeed" in flight_params_lower:
                thrust_col = next(col for col in self.qar_core_fields["engine_params"] if col.lower() == "thrust")
                speed_col = next(col for col in self.qar_core_fields["flight_params"] if col.lower() == "airspeed")
                
                if thrust_col in self.cleaned_df.columns and speed_col in self.cleaned_df.columns:
                    corr, p_val = stats.pearsonr(self.cleaned_df[thrust_col], self.cleaned_df[speed_col])
                    qar_specific_tests["æ¨åŠ›-é€Ÿåº¦ç›¸å…³æ€§"] = {
                        "ç›¸å…³ç³»æ•°": round(corr, 3),
                        "på€¼": round(p_val, 5),
                        "ä¸šåŠ¡è§£è¯»": "æ­£ç›¸å…³æ˜¾è‘—ï¼ˆp<0.05ï¼‰è¡¨æ˜æ¨åŠ›è°ƒèŠ‚ä¸é€Ÿåº¦æ§åˆ¶åŒ¹é…æ€§å¥½" if p_val<0.05 else "ç›¸å…³æ€§ä¸æ˜¾è‘—ï¼Œéœ€æ£€æŸ¥æ¨åŠ›æ§åˆ¶ç³»ç»Ÿ"
                    }
        
        # 2. ä¸åŒé£è¡Œé˜¶æ®µçš„å‚æ•°å·®å¼‚æ£€éªŒï¼ˆANOVAï¼‰
        if self.qar_core_fields.get("flight_phase") and self.qar_core_fields["flight_phase"] in self.cleaned_df.columns:
            phase_col = self.qar_core_fields["flight_phase"]
            if self.qar_core_fields.get("engine_params"):
                for col in self.qar_core_fields["engine_params"]:
                    if col in self.cleaned_df.columns:
                        try:
                            model = ols(f"{col} ~ C({phase_col})", data=self.cleaned_df).fit()
                            anova_table = sm.stats.anova_lm(model, typ=2)
                            f_val = anova_table['F'].iloc[0]
                            p_val = anova_table['PR(>F)'].iloc[0]
                            qar_specific_tests[f"{col}çš„é£è¡Œé˜¶æ®µå·®å¼‚"] = {
                                "Få€¼": round(f_val, 3),
                                "på€¼": round(p_val, 5),
                                "ä¸šåŠ¡è§£è¯»": "ä¸åŒé˜¶æ®µå‚æ•°å·®å¼‚æ˜¾è‘—ï¼ˆp<0.05ï¼‰ï¼Œç¬¦åˆæ­£å¸¸é£è¡Œé€»è¾‘" if p_val<0.05 else "é˜¶æ®µå‚æ•°å·®å¼‚ä¸æ˜¾è‘—ï¼Œå¯èƒ½å­˜åœ¨ä¼ æ„Ÿå™¨å¼‚å¸¸"
                            }
                        except Exception as e:
                            qar_specific_tests[f"{col}çš„é£è¡Œé˜¶æ®µå·®å¼‚"] = {
                                "é”™è¯¯": f"æ— æ³•è®¡ç®—: {str(e)}"
                            }
        
        if qar_specific_tests:
            results["QARä¸“é¡¹æ£€éªŒ"] = qar_specific_tests  # åŠ å…¥ç»“æœ
        self.stats_results = results
        return results
